{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQQuRvQIG-Bv"
      },
      "source": [
        "## Welcome to Lab 3 for Week 1 Day 4\n",
        "\n",
        "Today we're going to build something with immediate value!\n",
        "\n",
        "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
        "\n",
        "Please replace it with yours!\n",
        "\n",
        "I've also made a file called `summary.txt`\n",
        "\n",
        "We're not going to use Tools just yet - we're going to add the tool tomorrow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj0WztvBG-Bv"
      },
      "source": [
        "<table style=\"margin: 0; text-align: left; width:100%\">\n",
        "    <tr>\n",
        "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
        "            <img src=\"https://github.com/yatishkumarbn/agenticai_course/blob/main/assets/tools.png?raw=1\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
        "        </td>\n",
        "        <td>\n",
        "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
        "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs,\n",
        "            and we're also going to use the popular PyPDF2 PDF reader. You can get guides to these packages by asking\n",
        "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
        "            </span>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "oKDWCeyVHa9b",
        "outputId": "2c27a3a9-4533-4ab7-cd4c-1dd5162634b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.7.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.7.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "REgpAEMGHhdC",
        "outputId": "03ff4fdc-5b90-45be-a77d-5927fc1a0a2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.14)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QR1T7QJkG-Bw"
      },
      "outputs": [],
      "source": [
        "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
        "\n",
        "#from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from pypdf import PdfReader\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yXoPXnMG-Bw"
      },
      "outputs": [],
      "source": [
        "load_dotenv(override=True)\n",
        "openai = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Srw4gx50G-Bw"
      },
      "outputs": [],
      "source": [
        "reader = PdfReader(\"/content/Profile.pdf\")\n",
        "linkedin = \"\"\n",
        "for page in reader.pages:\n",
        "    text = page.extract_text()\n",
        "    if text:\n",
        "        linkedin += text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cYVfNTu4G-Bw",
        "outputId": "aecaaf9f-f1bc-4a7d-fb9c-a1eaa5770c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "Contact\n",
            "9886173433 (Mobile)\n",
            "yatishkumar.b.n@gmail.com\n",
            "www.linkedin.com/in/yatish-kumar-\n",
            "bn (LinkedIn)\n",
            "Top Skills\n",
            "Data-Driven Insights\n",
            "Team Building\n",
            "Revenue Management\n",
            "Languages\n",
            "English (Full Professional)\n",
            "Telugu\n",
            "Tamil\n",
            "Hindi\n",
            "Kannada\n",
            "Certifications\n",
            "Hortonworks Certified Associate\n",
            "Microsoft Certified: Azure AI\n",
            "Fundamentals\n",
            "Fundamentals of MCP\n",
            "Data Science and Bigdata Analytics\n",
            "Associate (EMCDSA)\n",
            "Microsoft Certified: Azure Data\n",
            "Fundamentals\n",
            "Honors-Awards\n",
            "Associate Performance Award\n",
            "Experian Excel Award\n",
            "Experian Excel Award\n",
            "Credit Excellence Award\n",
            "Spot Award\n",
            "Publications\n",
            "ELECTRONIC VOTING SYSTEM\n",
            "USING BLOCKCHAIN\n",
            "Yatish Kumar\n",
            "General Manager (OTT, Adtech, CLM) @ Airtel Digital | Data\n",
            "Science\n",
            "Bengaluru, Karnataka, India\n",
            "Summary\n",
            "Airtel Digital empowers businesses through innovative analytics and\n",
            "data-driven solutions, with a focus on Adtech, OTT, and CLM. As\n",
            "General Manager with over 7 months in this role and experience\n",
            "in data architecture and analytics, contributed to advancing Airtel\n",
            "Digital's digital strategies and operational efficiency. Demonstrated\n",
            "expertise in leading teams to solve complex problems using cutting-\n",
            "edge tools like Python, Databricks, and Azure Cloud.  \n",
            "Over 10+ years as a Data Science and Analytics leader, dedicated\n",
            "to guiding aspiring professionals to achieve their career goals.\n",
            "Known for designing scalable data solutions and mentoring teams\n",
            "in big data integration, enabling organizations to make smarter\n",
            "business decisions. Passionate about leveraging technology to\n",
            "deliver impactful results and foster innovation across the digital\n",
            "ecosystem.\n",
            "Experience\n",
            "Airtel Digital\n",
            "3 years 8 months\n",
            "General Manager (OTT, Adtech, CLM)\n",
            "December 2024 - Present (8 months)\n",
            "Greater Bengaluru Area\n",
            "Deputy General Manager (OTT, Adtech)\n",
            "January 2024 - December 2024 (1 year)\n",
            "Greater Bengaluru Area\n",
            "Head Of Analytics, Airtel Ads\n",
            "December 2021 - December 2023 (2 years 1 month)\n",
            "Bangalore Urban, Karnataka, India\n",
            "upGrad\n",
            "  Page 1 of 2   \n",
            "Data Science Mentor\n",
            "April 2019 - Present (6 years 4 months)\n",
            "Bangalore Urban, Karnataka, India\n",
            "Anheuser-Busch InBev\n",
            "Manager - Analytics\n",
            "May 2018 - November 2021 (3 years 7 months)\n",
            "Bangalore\n",
            "Dell EMC\n",
            "Consultant\n",
            "November 2014 - May 2018 (3 years 7 months)\n",
            "Bangalore\n",
            "Ciber\n",
            "Consultant (Working for DELL EMC)\n",
            "April 2014 - November 2014 (8 months)\n",
            "Bangalore\n",
            "Dell\n",
            "Software Dev Advisor\n",
            "June 2006 - February 2014 (7 years 9 months)\n",
            "Education\n",
            "Liverpool John Moores University\n",
            "Master of Science - MS, Data Science · (2019 - 2020)\n",
            "International Institute of Information Technology – Bangalore\n",
            "Post Graduate Diploma in Data Science, Data Science · (2017 - 2018)\n",
            "PES University\n",
            "Engineer’s Degree, Engineering · (2002 - 2006)\n",
            "  Page 2 of 2\n"
          ]
        }
      ],
      "source": [
        "print(linkedin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6u3cwwFiG-Bw"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    summary = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OaMaTQi0G-Bw"
      },
      "outputs": [],
      "source": [
        "name = \"Yatish\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "U3XRe2hQG-Bw"
      },
      "outputs": [],
      "source": [
        "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
        "particularly questions related to {name}'s career, background, skills and experience. \\\n",
        "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
        "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
        "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
        "If you don't know the answer, say so.\"\n",
        "\n",
        "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
        "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "blTVhplyG-Bw",
        "outputId": "efdf23e5-d483-4cda-c528-ff821e748663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You are acting as Yatish. You are answering questions on Yatish's website, particularly questions related to Yatish's career, background, skills and experience. Your responsibility is to represent Yatish for interactions on the website as faithfully as possible. You are given a summary of Yatish's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Yatish. I'm Data Science and Analytics Leader. I'm originally from Bangalore, India having experience in UK for 3 years.\\nI love all foods, particularly Spanish and Indian food. I'm not allergic, I love Hyderabad biriyani! I would love to mentor people looking for transition into Data career. I would love to eat jack fruit. I have a son who is 9 year old and his name is kiyansh. He going to Vidyashilpa school. I don't like APT or Blackpink songs.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\n9886173433 (Mobile)\\nyatishkumar.b.n@gmail.com\\nwww.linkedin.com/in/yatish-kumar-\\nbn (LinkedIn)\\nTop Skills\\nData-Driven Insights\\nTeam Building\\nRevenue Management\\nLanguages\\nEnglish (Full Professional)\\nTelugu\\nTamil\\nHindi\\nKannada\\nCertifications\\nHortonworks Certified Associate\\nMicrosoft Certified: Azure AI\\nFundamentals\\nFundamentals of MCP\\nData Science and Bigdata Analytics\\nAssociate (EMCDSA)\\nMicrosoft Certified: Azure Data\\nFundamentals\\nHonors-Awards\\nAssociate Performance Award\\nExperian Excel Award\\nExperian Excel Award\\nCredit Excellence Award\\nSpot Award\\nPublications\\nELECTRONIC VOTING SYSTEM\\nUSING BLOCKCHAIN\\nYatish Kumar\\nGeneral Manager (OTT, Adtech, CLM) @ Airtel Digital | Data\\nScience\\nBengaluru, Karnataka, India\\nSummary\\nAirtel Digital empowers businesses through innovative analytics and\\ndata-driven solutions, with a focus on Adtech, OTT, and CLM. As\\nGeneral Manager with over 7 months in this role and experience\\nin data architecture and analytics, contributed to advancing Airtel\\nDigital's digital strategies and operational efficiency. Demonstrated\\nexpertise in leading teams to solve complex problems using cutting-\\nedge tools like Python, Databricks, and Azure Cloud.  \\nOver 10+ years as a Data Science and Analytics leader, dedicated\\nto guiding aspiring professionals to achieve their career goals.\\nKnown for designing scalable data solutions and mentoring teams\\nin big data integration, enabling organizations to make smarter\\nbusiness decisions. Passionate about leveraging technology to\\ndeliver impactful results and foster innovation across the digital\\necosystem.\\nExperience\\nAirtel Digital\\n3 years 8 months\\nGeneral Manager (OTT, Adtech, CLM)\\nDecember 2024\\xa0-\\xa0Present\\xa0(8 months)\\nGreater Bengaluru Area\\nDeputy General Manager (OTT, Adtech)\\nJanuary 2024\\xa0-\\xa0December 2024\\xa0(1 year)\\nGreater Bengaluru Area\\nHead Of Analytics, Airtel Ads\\nDecember 2021\\xa0-\\xa0December 2023\\xa0(2 years 1 month)\\nBangalore Urban, Karnataka, India\\nupGrad\\n\\xa0 Page 1 of 2\\xa0 \\xa0\\nData Science Mentor\\nApril 2019\\xa0-\\xa0Present\\xa0(6 years 4 months)\\nBangalore Urban, Karnataka, India\\nAnheuser-Busch InBev\\nManager - Analytics\\nMay 2018\\xa0-\\xa0November 2021\\xa0(3 years 7 months)\\nBangalore\\nDell EMC\\nConsultant\\nNovember 2014\\xa0-\\xa0May 2018\\xa0(3 years 7 months)\\nBangalore\\nCiber\\nConsultant (Working for DELL EMC)\\nApril 2014\\xa0-\\xa0November 2014\\xa0(8 months)\\nBangalore\\nDell\\nSoftware Dev Advisor\\nJune 2006\\xa0-\\xa0February 2014\\xa0(7 years 9 months)\\nEducation\\nLiverpool John Moores University\\nMaster of Science - MS,\\xa0Data Science\\xa0·\\xa0(2019\\xa0-\\xa02020)\\nInternational Institute of Information Technology – Bangalore\\nPost Graduate Diploma in Data Science,\\xa0Data Science\\xa0·\\xa0(2017\\xa0-\\xa02018)\\nPES University\\nEngineer’s Degree,\\xa0Engineering\\xa0·\\xa0(2002\\xa0-\\xa02006)\\n\\xa0 Page 2 of 2\\n\\nWith this context, please chat with the user, always staying in character as Yatish.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "system_prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "g_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = g_api_key\n",
        "google_api_key = os.getenv('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "nIGICV1Dtqu5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
        "model_name = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "NGfhiOqPtFXd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "buB6YHtRG-Bw"
      },
      "outputs": [],
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
        "    #response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6g78ATwUG-Bw",
        "outputId": "921e8ae9-98c1-42f9-fb79-46b34c66d1d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d93876b4155d652792.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d93876b4155d652792.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "gr.ChatInterface(chat, type=\"messages\").launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CkG_xD_G-Bw"
      },
      "source": [
        "## A lot is about to happen...\n",
        "\n",
        "1. Be able to ask an LLM to evaluate an answer\n",
        "2. Be able to rerun if the answer fails evaluation\n",
        "3. Put this together into 1 workflow\n",
        "\n",
        "All without any Agentic framework!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqO6xOAxG-Bw"
      },
      "outputs": [],
      "source": [
        "# Create a Pydantic model for the Evaluation\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    is_acceptable: bool\n",
        "    feedback: str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny4AyER8G-Bw"
      },
      "outputs": [],
      "source": [
        "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
        "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
        "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
        "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
        "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
        "\n",
        "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
        "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5wyOyhtG-Bw"
      },
      "outputs": [],
      "source": [
        "def evaluator_user_prompt(reply, message, history):\n",
        "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
        "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
        "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
        "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
        "    return user_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmtjfGG7G-Bw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "gemini = OpenAI(\n",
        "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt7IRbpiG-Bx"
      },
      "outputs": [],
      "source": [
        "def evaluate(reply, message, history) -> Evaluation:\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
        "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
        "    return response.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPjwdhpyG-Bx"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
        "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "reply = response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In-NFjzpG-Bx"
      },
      "outputs": [],
      "source": [
        "reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9b6TFLpG-Bx"
      },
      "outputs": [],
      "source": [
        "evaluate(reply, \"do you hold a patent?\", messages[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzYpGe7RG-Bx"
      },
      "outputs": [],
      "source": [
        "def rerun(reply, message, history, feedback):\n",
        "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
        "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
        "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
        "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgaG2g09G-Bx"
      },
      "outputs": [],
      "source": [
        "def chat(message, history):\n",
        "    if \"patent\" in message:\n",
        "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
        "              it is mandatory that you respond only and entirely in pig latin\"\n",
        "    else:\n",
        "        system = system_prompt\n",
        "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "    reply =response.choices[0].message.content\n",
        "\n",
        "    evaluation = evaluate(reply, message, history)\n",
        "\n",
        "    if evaluation.is_acceptable:\n",
        "        print(\"Passed evaluation - returning reply\")\n",
        "    else:\n",
        "        print(\"Failed evaluation - retrying\")\n",
        "        print(evaluation.feedback)\n",
        "        reply = rerun(reply, message, history, evaluation.feedback)\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY1FRKpVG-Bx"
      },
      "outputs": [],
      "source": [
        "gr.ChatInterface(chat, type=\"messages\").launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFJHzaAmG-Bx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlWyAiRaG-Bx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}